{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49cb96e2",
   "metadata": {},
   "source": [
    "# Keras with TensorFlow: Python Deep Learning and Neural Networks \n",
    "\n",
    "This is a fairly basic course that sets the groundwork to working with Keras/ML/Deep learning/AI etc., I highly recommend checking out the original video: \n",
    "https://www.youtube.com/watch?v=qFJeN9V1ZsI&t=8778s&ab_channel=freeCodeCamp.org\n",
    "\n",
    "This first script covers the following topics (I'm afraid my titles may not correspond exactly to these, but they are similar)\n",
    "\n",
    "- ⌨ Create an Artificial Neural Network with TensorFlow's Keras API\n",
    "- ⌨Train an Artificial Neural Network with TensorFlow's Keras API\n",
    "- ⌨Build a Validation Set With TensorFlow's Keras API\n",
    "- ⌨Neural Network Predictions with TensorFlow's Keras API\n",
    "- ⌨Create a Confusion Matrix for Neural Network Predictions\n",
    "\n",
    "The second script roughly contains the following:\n",
    "\n",
    "- ⌨Save and Load a Model with TensorFlow's Keras API\n",
    "- ⌨Image Preparation for CNNs with TensorFlow's Keras API\n",
    "- ⌨Build and Train a CNN with TensorFlow's Keras API\n",
    "- ⌨CNN Predictions with TensorFlow's Keras API\n",
    "- ⌨Build a Fine-Tuned Neural Network with TensorFlow's Keras API\n",
    "- ⌨Train a Fine-Tuned Neural Network with TensorFlow's Keras API\n",
    "- ⌨Predict with a Fine-Tuned Neural Network with TensorFlow's Keras API\n",
    "- ⌨MobileNet Image Classification with TensorFlow's Keras API\n",
    "- ⌨Process Images for Fine-Tuned MobileNet with TensorFlow's Keras API\n",
    "- ⌨Fine-Tuning MobileNet on Custom Data Set with TensorFlow's Keras API\n",
    "- ⌨Data Augmentation with TensorFlow' Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37edea79",
   "metadata": {},
   "source": [
    "## Building a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5342e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x - recives data during training whenever we call the \"fit\" function. Our data will be in a numpy array\n",
    "#y - contains the corresponding labels (target data) needs to be the same as x, will be in a numpy array too. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728776e",
   "metadata": {},
   "source": [
    "### Data prep and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b567e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle #scikitlearn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e478358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two empty lists, corresponding samples and labels.\n",
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b7d510",
   "metadata": {},
   "source": [
    "Example data: \n",
    "\n",
    "- Experimental drug tested on people from ages 13-100 in clinical trial\n",
    "- trial has *2100* people. Half are **under 65**, the other half are **65 or older**.  \n",
    "- 95% of patients 65 and older experienced side effects \n",
    "- 95% of those 65 and under experienced no side effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb58d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50): \n",
    "    # the ~5% of younger individuals who did have side effects (approx 50)\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1) # 1 means they did have side effects\n",
    "    \n",
    "    # the ~5% of older individuals who DID NOT have side effects (approx 50)\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0) # 0 means they did not did have side effects\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "237561f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    # the ~95% of younger individuals who DID NOT have side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    # the ~95% of older individuals who did have side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca3a974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
    
   "source": [
    "for i in train_labels: # these are the labels for having side effects (1) or not having side effects (0)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5837a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to change the data so it can work for the fit function, so we need to convert both to numpy arrays. \n",
    "#then, we shuffle both our train labels and train samples to get rid of any order from data gen process:\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54254ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling down our data to a  0 to 1 scale can make our neural network more efficient, thats what we do now: \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1)) #creates a feature range from 0 to 1\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1)) # now we compress our age range from 13-100, down to a 0 to 1 scale\n",
    "# the -1 to 1 is just a formality, because fit transform doesn't accept 1D data by default, we just have to change it this way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9fee633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "#checking the scaled data, \n",
    "for i in scaled_train_samples: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36529c4e",
   "metadata": {},
   "source": [
    "### simple tf.keras Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc2a6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip uninstall tensorflow \n",
    "#%pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d671334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]\n",
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "#tf version:\n",
    "\n",
    "import sys\n",
    "print (sys.version)\n",
    "# 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# my output was => 1.13.1\n",
    "\n",
    "#https://www.tensorflow.org/install/source\n",
    "#see, that tensorflow_gpu-2.8.0 needs: CUDA Toolkit v11.2, cuDNN SDK v8.1\n",
    "\n",
    "#https://developer.nvidia.com/cuda-toolkit-archive\n",
    "#select: CUDA Toolkit 10.0 and download base installer (2 GB)\n",
    "#installation settings: select only CUDA\n",
    "#my installation path was: C:\\Users\\klaws\\AppData\\Local\\Temp\\CUDA\n",
    "\n",
    "#https://developer.nvidia.com/rdp/cudnn-archive (needs registration, but it is simple)\n",
    "#select \"Download cuDNN v8.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feddb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming you already have tensorflow\n",
    "#conda install -c conda-forge keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam #these last two are for training the model, not building it. \n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "940f7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to try and run on GPU, note I had trouble configuring gpu usage in WSL for tensorflow. \n",
    "\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#print(\"Num GPUs Available: \", len(physical_devices))\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8118229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model itself: \n",
    "\n",
    "\"\"\"\n",
    "this is a list of layers, the first layer is actually the second layer overall (this is the first hidden layer, \n",
    "we don't explicity define the input layer, but we tell it using the input_shape parameter, it accepts this and then\n",
    "passes it to the first hidden layer. \n",
    "\n",
    "An activation function in a neural network defines how the weighted sum of the input is transformed into an output \n",
    "from a node or nodes in a layer of the network. Rectified Linear Unit (ReLU) is one such function.\n",
    "\n",
    "more on this: \n",
    "\n",
    "https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\n",
    "\"\"\"\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation = 'relu'), #16 nodes/neurons, this is pretty arbitrary. \n",
    "    Dense(units=32, activation='relu'), #another hidden dense layer. \n",
    "    Dense(units=2, activation = 'softmax') #we generally deploy softmax on the output layer of neural networks. \n",
    "]) \n",
    "\n",
    "#output layer, two units - two possible classes, patient with or without side effects\n",
    "#softmax is probability for each output class (for any given patient). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0f18de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 16)                32        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#visual architecture of our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1883a0",
   "metadata": {},
   "source": [
    "### Training the artifical neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee7144a",
   "metadata": {},
   "source": [
    "- ADAM is a common optimizer function, **An optimizer is a function or an algorithm that modifies the attributes of the neural network**, such as weights and learning rate. Thus, it helps in reducing the overall loss and improve the accuracy\n",
    "\n",
    "- **What is loss?** The Loss Function is one of the important components of Neural Networks. Loss is nothing but a prediction error of a Neural Net. In simple words, the Loss is used to calculate the gradients. And gradients are used to update neural net weightings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1460335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to judge the model by accuracy. \n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss ='sparse_categorical_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2fd5db",
   "metadata": {},
   "source": [
    "- *Batch size*: How many samples are to be passed and processed through the neural network at one time\n",
    "- *Epochs*: How many times the neural network will train on all of our data (30x before completing the training process)\n",
    "- *Shuffle*:True by default, but the data is being shuffled by default to remove any order in data.\n",
    "- *Verbose*: the most verbose of output messages, can be 0,1, or 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29bc1617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "210/210 - 0s - loss: 0.6622 - accuracy: 0.5310 - 474ms/epoch - 2ms/step\n",
      "Epoch 2/30\n",
      "210/210 - 0s - loss: 0.6237 - accuracy: 0.6338 - 123ms/epoch - 585us/step\n",
      "Epoch 3/30\n",
      "210/210 - 0s - loss: 0.5812 - accuracy: 0.7181 - 123ms/epoch - 586us/step\n",
      "Epoch 4/30\n",
      "210/210 - 0s - loss: 0.5421 - accuracy: 0.7724 - 124ms/epoch - 592us/step\n",
      "Epoch 5/30\n",
      "210/210 - 0s - loss: 0.5037 - accuracy: 0.8100 - 123ms/epoch - 586us/step\n",
      "Epoch 6/30\n",
      "210/210 - 0s - loss: 0.4664 - accuracy: 0.8314 - 123ms/epoch - 586us/step\n",
      "Epoch 7/30\n",
      "210/210 - 0s - loss: 0.4311 - accuracy: 0.8595 - 123ms/epoch - 585us/step\n",
      "Epoch 8/30\n",
      "210/210 - 0s - loss: 0.3993 - accuracy: 0.8748 - 121ms/epoch - 575us/step\n",
      "Epoch 9/30\n",
      "210/210 - 0s - loss: 0.3713 - accuracy: 0.8990 - 120ms/epoch - 572us/step\n",
      "Epoch 10/30\n",
      "210/210 - 0s - loss: 0.3481 - accuracy: 0.8990 - 120ms/epoch - 570us/step\n",
      "Epoch 11/30\n",
      "210/210 - 0s - loss: 0.3294 - accuracy: 0.9114 - 120ms/epoch - 573us/step\n",
      "Epoch 12/30\n",
      "210/210 - 0s - loss: 0.3146 - accuracy: 0.9181 - 123ms/epoch - 587us/step\n",
      "Epoch 13/30\n",
      "210/210 - 0s - loss: 0.3025 - accuracy: 0.9286 - 120ms/epoch - 570us/step\n",
      "Epoch 14/30\n",
      "210/210 - 0s - loss: 0.2932 - accuracy: 0.9290 - 121ms/epoch - 575us/step\n",
      "Epoch 15/30\n",
      "210/210 - 0s - loss: 0.2855 - accuracy: 0.9338 - 122ms/epoch - 579us/step\n",
      "Epoch 16/30\n",
      "210/210 - 0s - loss: 0.2800 - accuracy: 0.9286 - 124ms/epoch - 592us/step\n",
      "Epoch 17/30\n",
      "210/210 - 0s - loss: 0.2749 - accuracy: 0.9352 - 124ms/epoch - 589us/step\n",
      "Epoch 18/30\n",
      "210/210 - 0s - loss: 0.2711 - accuracy: 0.9357 - 122ms/epoch - 583us/step\n",
      "Epoch 19/30\n",
      "210/210 - 0s - loss: 0.2680 - accuracy: 0.9367 - 121ms/epoch - 575us/step\n",
      "Epoch 20/30\n",
      "210/210 - 0s - loss: 0.2652 - accuracy: 0.9386 - 121ms/epoch - 577us/step\n",
      "Epoch 21/30\n",
      "210/210 - 0s - loss: 0.2626 - accuracy: 0.9343 - 119ms/epoch - 567us/step\n",
      "Epoch 22/30\n",
      "210/210 - 0s - loss: 0.2609 - accuracy: 0.9376 - 119ms/epoch - 568us/step\n",
      "Epoch 23/30\n",
      "210/210 - 0s - loss: 0.2591 - accuracy: 0.9410 - 120ms/epoch - 572us/step\n",
      "Epoch 24/30\n",
      "210/210 - 0s - loss: 0.2576 - accuracy: 0.9386 - 122ms/epoch - 581us/step\n",
      "Epoch 25/30\n",
      "210/210 - 0s - loss: 0.2560 - accuracy: 0.9400 - 123ms/epoch - 584us/step\n",
      "Epoch 26/30\n",
      "210/210 - 0s - loss: 0.2548 - accuracy: 0.9390 - 124ms/epoch - 591us/step\n",
      "Epoch 27/30\n",
      "210/210 - 0s - loss: 0.2536 - accuracy: 0.9367 - 120ms/epoch - 572us/step\n",
      "Epoch 28/30\n",
      "210/210 - 0s - loss: 0.2526 - accuracy: 0.9410 - 121ms/epoch - 578us/step\n",
      "Epoch 29/30\n",
      "210/210 - 0s - loss: 0.2514 - accuracy: 0.9400 - 121ms/epoch - 575us/step\n",
      "Epoch 30/30\n",
      "210/210 - 0s - loss: 0.2509 - accuracy: 0.9414 - 118ms/epoch - 563us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e84261a50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2)\n",
    "#remember, in this case, an accurary of 50% would mean no better than chance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084456ea",
   "metadata": {},
   "source": [
    "### Building a validation set with TF's Keras API\n",
    "\n",
    "- We want an accurate model, with low loss and high accuracy. However, we don't just take a model and train it for the sake of training it in real life. Therefore, we use something called a validation set, which helps us tell how well our model is generalizing. \n",
    "\n",
    "- Before the training begins, we can take a subset. Essentially, we can prevent overfitting. There are two ways we can create a validation set using tf.keras.sequential. The first way is to create a data structure to hold this data, and then place the data in this the same way we do for the training set. \n",
    "\n",
    "- This will be a tuple of Numpy arrays/tensors, i.e. valid set = (x_val, y_val). wher x_val is a numpy array or tensor containing validiation samples, and y_val contains validation labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b875cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now pass an additional parameter, Validation as another parameter to model.fit() \n",
    "\n",
    "#valid set = tuple(x_val, y_val)\n",
    "#e.g. x:13,54,65,23,80 and y: 0,1,1,0,1, as a numpy array of tuples would be (13,0),(54,1),(65,1),(23,0), and (80,1) \n",
    "\n",
    "#model.fit(\n",
    "#    x=scaled_train_samples, \n",
    "#    y=train_labels,\n",
    "#    validation_data= valid_set,\n",
    "#    batch_size=10,\n",
    "#    epochs=30, \n",
    "#    verbose=2\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b472c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "189/189 - 0s - loss: 0.2532 - accuracy: 0.9397 - val_loss: 0.2197 - val_accuracy: 0.9524 - 227ms/epoch - 1ms/step\n",
      "Epoch 2/30\n",
      "189/189 - 0s - loss: 0.2527 - accuracy: 0.9413 - val_loss: 0.2190 - val_accuracy: 0.9524 - 135ms/epoch - 712us/step\n",
      "Epoch 3/30\n",
      "189/189 - 0s - loss: 0.2519 - accuracy: 0.9413 - val_loss: 0.2180 - val_accuracy: 0.9524 - 154ms/epoch - 815us/step\n",
      "Epoch 4/30\n",
      "189/189 - 0s - loss: 0.2512 - accuracy: 0.9402 - val_loss: 0.2174 - val_accuracy: 0.9524 - 138ms/epoch - 729us/step\n",
      "Epoch 5/30\n",
      "189/189 - 0s - loss: 0.2509 - accuracy: 0.9413 - val_loss: 0.2166 - val_accuracy: 0.9524 - 134ms/epoch - 708us/step\n",
      "Epoch 6/30\n",
      "189/189 - 0s - loss: 0.2503 - accuracy: 0.9413 - val_loss: 0.2159 - val_accuracy: 0.9524 - 134ms/epoch - 710us/step\n",
      "Epoch 7/30\n",
      "189/189 - 0s - loss: 0.2499 - accuracy: 0.9402 - val_loss: 0.2152 - val_accuracy: 0.9524 - 144ms/epoch - 762us/step\n",
      "Epoch 8/30\n",
      "189/189 - 0s - loss: 0.2495 - accuracy: 0.9423 - val_loss: 0.2145 - val_accuracy: 0.9524 - 132ms/epoch - 700us/step\n",
      "Epoch 9/30\n",
      "189/189 - 0s - loss: 0.2492 - accuracy: 0.9413 - val_loss: 0.2139 - val_accuracy: 0.9524 - 137ms/epoch - 726us/step\n",
      "Epoch 10/30\n",
      "189/189 - 0s - loss: 0.2487 - accuracy: 0.9413 - val_loss: 0.2132 - val_accuracy: 0.9524 - 133ms/epoch - 705us/step\n",
      "Epoch 11/30\n",
      "189/189 - 0s - loss: 0.2484 - accuracy: 0.9413 - val_loss: 0.2127 - val_accuracy: 0.9524 - 134ms/epoch - 710us/step\n",
      "Epoch 12/30\n",
      "189/189 - 0s - loss: 0.2481 - accuracy: 0.9423 - val_loss: 0.2120 - val_accuracy: 0.9524 - 134ms/epoch - 707us/step\n",
      "Epoch 13/30\n",
      "189/189 - 0s - loss: 0.2476 - accuracy: 0.9402 - val_loss: 0.2119 - val_accuracy: 0.9524 - 133ms/epoch - 702us/step\n",
      "Epoch 14/30\n",
      "189/189 - 0s - loss: 0.2475 - accuracy: 0.9429 - val_loss: 0.2112 - val_accuracy: 0.9524 - 132ms/epoch - 697us/step\n",
      "Epoch 15/30\n",
      "189/189 - 0s - loss: 0.2473 - accuracy: 0.9429 - val_loss: 0.2106 - val_accuracy: 0.9524 - 129ms/epoch - 683us/step\n",
      "Epoch 16/30\n",
      "189/189 - 0s - loss: 0.2469 - accuracy: 0.9429 - val_loss: 0.2102 - val_accuracy: 0.9524 - 136ms/epoch - 719us/step\n",
      "Epoch 17/30\n",
      "189/189 - 0s - loss: 0.2468 - accuracy: 0.9429 - val_loss: 0.2098 - val_accuracy: 0.9524 - 133ms/epoch - 704us/step\n",
      "Epoch 18/30\n",
      "189/189 - 0s - loss: 0.2465 - accuracy: 0.9418 - val_loss: 0.2092 - val_accuracy: 0.9524 - 137ms/epoch - 723us/step\n",
      "Epoch 19/30\n",
      "189/189 - 0s - loss: 0.2463 - accuracy: 0.9444 - val_loss: 0.2089 - val_accuracy: 0.9524 - 138ms/epoch - 731us/step\n",
      "Epoch 20/30\n",
      "189/189 - 0s - loss: 0.2459 - accuracy: 0.9413 - val_loss: 0.2085 - val_accuracy: 0.9524 - 135ms/epoch - 713us/step\n",
      "Epoch 21/30\n",
      "189/189 - 0s - loss: 0.2455 - accuracy: 0.9413 - val_loss: 0.2082 - val_accuracy: 0.9524 - 145ms/epoch - 768us/step\n",
      "Epoch 22/30\n",
      "189/189 - 0s - loss: 0.2454 - accuracy: 0.9413 - val_loss: 0.2079 - val_accuracy: 0.9524 - 139ms/epoch - 737us/step\n",
      "Epoch 23/30\n",
      "189/189 - 0s - loss: 0.2453 - accuracy: 0.9418 - val_loss: 0.2076 - val_accuracy: 0.9524 - 134ms/epoch - 708us/step\n",
      "Epoch 24/30\n",
      "189/189 - 0s - loss: 0.2449 - accuracy: 0.9413 - val_loss: 0.2071 - val_accuracy: 0.9524 - 135ms/epoch - 715us/step\n",
      "Epoch 25/30\n",
      "189/189 - 0s - loss: 0.2448 - accuracy: 0.9429 - val_loss: 0.2067 - val_accuracy: 0.9524 - 147ms/epoch - 777us/step\n",
      "Epoch 26/30\n",
      "189/189 - 0s - loss: 0.2447 - accuracy: 0.9418 - val_loss: 0.2068 - val_accuracy: 0.9571 - 151ms/epoch - 801us/step\n",
      "Epoch 27/30\n",
      "189/189 - 0s - loss: 0.2445 - accuracy: 0.9471 - val_loss: 0.2062 - val_accuracy: 0.9524 - 138ms/epoch - 732us/step\n",
      "Epoch 28/30\n",
      "189/189 - 0s - loss: 0.2443 - accuracy: 0.9413 - val_loss: 0.2059 - val_accuracy: 0.9524 - 137ms/epoch - 726us/step\n",
      "Epoch 29/30\n",
      "189/189 - 0s - loss: 0.2440 - accuracy: 0.9413 - val_loss: 0.2056 - val_accuracy: 0.9524 - 140ms/epoch - 742us/step\n",
      "Epoch 30/30\n",
      "189/189 - 0s - loss: 0.2440 - accuracy: 0.9413 - val_loss: 0.2056 - val_accuracy: 0.9571 - 139ms/epoch - 738us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNOTE: Unless your data is already shuffled, you risk bias, because validation split takes the last 10% in this case,\\nIF that last 10% of the data had all the people who did have side effects, it would remove those from the training data, and create an \\nunrepresenative validation set. \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#However, it's also just easier to let Keras make this for us. \n",
    "\n",
    "model.fit(\n",
    "    x=scaled_train_samples, \n",
    "    y=train_labels,\n",
    "    validation_split = 0.1, # the last 10% of our training set \n",
    "    batch_size=10,\n",
    "    epochs=30, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "NOTE: Unless your data is already shuffled, you risk bias, because validation split takes the last 10% in this case,\n",
    "IF that last 10% of the data had all the people who did have side effects, it would remove those from the training data, and create an \n",
    "unrepresenative validation set. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9627df",
   "metadata": {},
   "source": [
    "### Building a test set with TF's Keras API\n",
    "\n",
    "Inference - The model takes things it's learned in training, and then infer things about what it's shown. Typically, after the model is trained and validated, we then use it it to infer based on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d3d5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The test and training data should be prepared in the same format as the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bce257db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []\n",
    "\n",
    "for i in range(50): \n",
    "    # the ~5% of younger individuals who did have side effects (approx 50)\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1) # 1 means they did have side effects\n",
    "    \n",
    "    # the ~5% of older individuals who DID NOT have side effects (approx 50)\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0) # 0 means they did not did have side effects\n",
    "    \n",
    "for i in range(1000): #\n",
    "    # the ~95% of younger individuals who DID NOT have side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    # the ~95% of older individuals who did have side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1776b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#again, we want to rescale the data as we did previously\n",
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffd37125",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c200e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in scaled_test_samples:\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2ab13",
   "metadata": {},
   "source": [
    "Now let's predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1091138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d32e698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)\n",
    "    \n",
    "    # for each element in our test set, we get a probability of the patient NOT experiencing a side effect on the left, and experiencing a side effect on the right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd0a3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, we can round these these predictions based on which is more likely, e.g. [0.30173883 0.69826114], as the right is larger, we would assume the patient will have a side effect. \n",
    "rounded_predictions = np.argmax(predictions, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "473389fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      
     ]
    }
   ],
   "source": [
    "#gives us the larger probability of the above, as we can see from the 1st sample, they are more likely to not\n",
    "#the 1st sample indeed has the higher probabilty of having side effects.\n",
    "\n",
    "for i in rounded_predictions: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f367f09",
   "metadata": {},
   "source": [
    "### Creating a confusion matrix to visualize our results: \n",
    "\n",
    "Using the predictions we passed to the np.argmax(), we can now visualize these predictions easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dc145e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the corrrect libraries: \n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7021fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred = rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b66e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This can be copied directly from the sklearn website, essentially it creates the confusion plot matrix. \n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize = False, title=\"Confusion Matrix\", cmap=plt.cm.Blues): \n",
    "    \"\"\"\n",
    "    This function prints andp lots the confusion matrix/ \n",
    "    Normalization can be applied by setting \"normalize=ture\"\n",
    "    \"\"\"\n",
    "    plt.imshow(cm,interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks,classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,i, cm[i,j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37b6e4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1000   50]\n",
      " [  50 1000]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now we define our plot labels, and can then pass them to the plot_confusion_matrix function, along with our cm itself, and title. \n",
    "\n",
    "cm_plot_labels = ['no_side_effects', 'has_side_effects']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title = 'Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa771cd",
   "metadata": {},
   "source": [
    "So reading the confusion matrix, we see that it predicted that 975 had no side effects correctly, and correctly predicted when 1001 did have side effects. However, it predicted that 49 had no side effects when they did, and 75 had predicted side effects, but did not. Overall, it correctly predicted 1976/2100 or ~94%. Note this will change a little bit each time you run it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7f665e",
   "metadata": {},
   "source": [
    "### Saving and Loading a Keras Sequential Model: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a35469f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\klaws\\\\OneDrive - Broken String Biosciences Ltd\\\\Desktop\\\\Keras'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() # to check your current working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc192689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st way: check if model exists and if not, save the model to the disk. This is the most comphrehensive way to save the model.\n",
    "#note: An H5 file is a data file saved in the Hierarchical Data Format (HDF). It contains multidimensional arrays of scientific data. for me, I've simply saved this in a place called models in my working directory\n",
    "\n",
    "import os.path \n",
    "if os.path.isfile('models/medical_trial_model.h5') is False: \n",
    "    model.save('models/medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8dc94b",
   "metadata": {},
   "source": [
    "This function saves: \n",
    "- the model architecture, allowing us to recreate the model \n",
    "- the model weights \n",
    "- the training configuration(loss, optimizer)\n",
    "- the optimizer state (meaning we can pick up exactly from where we left off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b8c2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model #need to import the load function model\n",
    "new_model = load_model('models/medical_trial_model.h5') #pointing to where the saved model is one disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7a00792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 16)                32        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4eca460e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4acd030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizer_v2.adam.Adam at 0x15e8fe05f90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87087e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd way: model.to_json(): only if we want to save the model architecture: \n",
    "\n",
    "json_string=model.to_json()\n",
    "\n",
    "#we could also save it as a YAML string, like below: \n",
    "#save as YAML \n",
    "#yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd308473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_3_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_4\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_5\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.8.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string # visualising the json architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7d69160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "model_architecture=model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "028d4f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 16)                32        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e939f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 option: if you only need to save the weights, you can do that to, like so:\n",
    "\n",
    "#will store the weights in a folder called models in your working directory if it doesn't already exist. \n",
    "import os.path \n",
    "if os.path.isfile('models/my_model_weights.h5') is False: \n",
    "    model.save_weights('models/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dfacfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thing is, if we didn't save the previous model, then although we would have the weights, we would have a model to load them into. \n",
    "#this step recreates the architecture of our model above\n",
    "\n",
    "model2 = Sequential([\n",
    "    Dense(units=16, input_shape=(1,),activation='relu'),\n",
    "    Dense(units=32, activation = 'relu'),\n",
    "    Dense(units=2, activation= 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ef660f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('models/my_model_weights.h5') #we could load these into a model which had 5 layers, as it wouldn't match.\n",
    "                                                  #our model only had 3 layers (2 hidden and one output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "561b21c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99a31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
